# ************************************************************************
# *********** DEFAULT CONFIGURATION: DO NOT CHANGE THIS FILE *************
# ************************************************************************
 

## BACKEND c_clause handler options ######################################

# Example:
# from c_clause import DataHandler, QAHandler
# from clause.config.options import Options
# opts = Options()
# loader = DataHandler(opts.flatS("data_handler"))
# qa = QAHandler(opts.flatS("qa_handler"))


# loads rulesets and datasets
data_handler:
  # Z rules
  use_zero_rules: True
  z_weight: 0.01
  # U_c rules
  use_u_c_rules: True
  # B rules
  use_b_rules: True
  b_max_branching_factor: -1 #-1 for off
  # U_d rules
  use_u_d_rules: True
  d_weight: 0.01
  d_max_branching_factor: -1 #-1 for off
  # Uxxc rules
  use_u_xxc_rules: True
  # Uxxd rules
  use_u_xxd_rules: True
  ## laplace smoothing applied to all rules
  ## confidence = num_correct_predictions / (num_unseen+num_predictions)
  rule_num_unseen: 5

# calculates rankings based on the target set loaded into DataLoader
ranking_handler:
  aggregation_function: "maxplus"
  num_preselect: -1 #-1 for off
  topk: 100
  filter_w_train: True
  filter_w_target: True
  disc_at_least: 10 # -1 for off, must not be bigger than topk
  # choose between "random" / "frequency"
  tie_handling: "frequency"
  # -1 for using ALL available threads
  num_threads: -1 

# calculates answer candidates and scores based on 
# questions (h, r, ?) and (?, r, t)
qa_handler:
  # whether to cache the rules that predicted the query candidates,
  # can be retrieved with handler.get_rules(bool).
  # Turn off for efficiency.
  collect_rules: False
  aggregation_function: "maxplus"
  num_preselect: -1 #-1 for off
  topk: 100
  filter_w_train: True
  disc_at_least: 10 # -1 for off, must not be bigger than topk
  # choose between "random" / "frequency"
  tie_handling: "frequency"
  # -1 for using ALL available threads
  num_threads: -1 

# given input rules, calculates materialization (predictions)
# and stats (num_pred, num_true_preds)
rules_handler:
  # whether to store triple predictions 
  # and stats (num_pred, num_true)
  # to obtained with handler.get_predictions(bool), handler.get_statistics()
  collect_predictions: True
  collect_statistics: True
  num_threads: -1 #-1 for ALL available threads

# given input triples, calculates scores and can output all
# predicting rules + groundings (explanations)
prediction_handler:
  collect_explanations: False
  aggregation_function: "maxplus"
  # for a given triple stop rule application if it was predicted by the
  # num_top_rules with the highest confidences
  num_top_rules: 5 
  num_threads: -1 #-1 for ALL available threads


## FRONTEND clause options ###############################################

io:
  rule_format: "PyClause"
learning:
  # chose betweeen:
  # "anyburl" / "hybrid" (mixing anyburl any nanytorm) / "nanytorm" / "amie"
  mode: "amie"  
  anyburl:
    time: 60
    # you can set any raw options supported by AnyBURL
    raw:
      MAX_LENGTH_CYCLIC: 3
      THRESHOLD_CORRECT_PREDICTIONS: 2
      THRESHOLD_CONFIDENCE: 0.0001
  amie:
    raw: # the -symbol infront of each param is added automatically
      mins: 2
      maxad: 4 # number of atoms = 1 head atom + body atoms
      minhc: 0.0001
      minpca: 0.0001
  torm:
    # if set to false, rules that do not make any wrong prediction are surpressed
    tautology: False 
    b:
      active: True
      confidence: 0.0001
      support: 2
      length: 3
      batchsize: 1000
    uc:
      active: True
      confidence: 0.0001
      support: 2
    ud:
      active: True
      confidence: 0.0001
      support: 2
    z:
      active: True
      confidence: 0.0001
      support: 2
    xx_uc:
      active: True
      confidence: 0.0001
      support: 2
    xx_ud:
      active: True
      confidence: 0.0001
      support: 2