# ************************************************************************
# *********** DEFAULT CONFIGURATION: DO NOT CHANGE THIS FILE *************
# ************************************************************************
 

## c_clause handler options #############################################

# Example:
# from c_clause import Loader, QAHandler
# from clause.config.options import Options
# opts = Options()
# opts.set("loader.load_zero_rules", False)
# opts.set("loader.b_min_support", 10)
# loader = Loader(opts.get("loader"))
# qa = QAHandler(opts.get("qa_handler"))


###  Loader loads rulesets and datasets
###  the options can be used to filter/ignore some rules

# 'r_num_unseen' option:
# laplace smoothing applied to rule type 'r' for calculating confidence
# conf = support / (num_unseen+num_body_groundings)

# 'r_min_support' option:
#  dont load rules of type 'r' if they have a lower support as 'r_min_support'
# 'r_min_preds' option: as above for the overall number of triple predicitions
# 'r_min_confidence': as above; note: confidence here is without laplace smooting
# 'r_max_length' option: as above; length refers to the number of body atoms
loader:

  ## B rules
  # parsable example: "h(X,Y) <= b1(A,X), b2(A,Y)"
  load_b_rules: True
  b_max_branching_factor: -1 #-1 for off
  b_num_unseen: 5
  b_min_support: 2
  b_min_preds: 2
  b_min_conf: 0.0001
  b_max_length: -1
 
  ## U_c rules
  # parsable examples (c and d being entities in the graph):
  # "h(X,c) <= b1(X,d)"
  # "h(c,Y) <= b1(Y,A), b2(d,A)" 
  load_u_c_rules: True
  c_num_unseen: 5
  c_min_support: 2
  c_min_preds: 2
  c_min_conf: 0.0001
  c_max_length: -1

  ##  U_d rules
  # parsable examples (c being an entity in the graph):
  # "h(X,c) <= b1(A,X), b2(A,B)" 
  # "h(X,c) <= b1(X,A)"
  load_u_d_rules: True
  # weight that is multiplied with the confidence
  d_weight: 0.01
  d_max_branching_factor: -1 #-1 for off
  d_num_unseen: 5
  d_min_support: 2
  d_min_preds: 2
  d_min_conf: 0.0001
  d_max_length: -1

  ## Z rules
  # parsable example (c being an entity in the graph): "h(X,c) <="
  # can only be used for qa or ranking not for PredictionHandler
  # has always length 1
  load_zero_rules: True
  # weight that is multiplied with the confidence
  z_weight: 0.1
  z_num_unseen: 5
  z_min_support: 2
  z_min_preds: 2
  z_min_conf: 0.0001

  ## U_xxc rules
  # parsable example: "h(X,X) <= b1(X,c)" (c being an entity in the graph)
  # has always length 1
  load_u_xxc_rules: True
  xxc_num_unseen: 5
  xxc_min_support: 2
  xxc_min_preds: 2
  xxc_min_conf: 0.0001

  ## U_xxd rules
  # parsable example: "h(X,X) <= b1(X,A)"
  # has always length 1
  load_u_xxd_rules: True
  xxd_num_unseen: 5
  xxd_min_support: 2
  xxd_min_preds: 2
  xxd_min_conf: 0.0001


# calculates rankings based on the target set loaded into DataLoader
ranking_handler:
  # whether to cache the rules that predicted the query candidates,
  # can be retrieved with handler.get_rules(bool, string:headOrTailRanking)
  # turn off for efficiency.
  collect_rules: False
  # number of candidates to calculate
  topk: 100
  # select from "maxplus" / "noisyor"
  # maxplus scores of a ranking will be of the highest predicting rule
  # candidate discrimination is based on comparing the sequences of predicting
  # rules confidences lexicographically
  # noisyor scores and ranking is based on sorting the noisy-or product
  # the noisy-or sorting is based on -\sum_i(log(1-conf_i)) and transformed
  # berfore outputted; this mitigates floating point considerations 
  aggregation_function: "maxplus"

  ### stopping criteria for rule application

  # stop rule application for a query if topk candidates are calculated AND at least disc_at_least
  # of the best candidates are fully discriminated, i.e, they are pairwise distinct in regard
  # to their predicting rules
  # recommended values: 10 or 20 under topk=100
  disc_at_least: 10 # -1 for off, must not be bigger than topk

  # stop rule application for a query as soon as hard_stop_at candidates
  # are found (ignoring topk); set the value to topk under maxplus to achieve max-aggregation
  # scores for all candidates very fast without getting a properly discriminated ranking
  # recommended value: -1
  hard_stop_at: -1 #-1 for off

  # stops adding predicting rules to a candidate of a query if already num_top_rules
  # predicted the candidate; if all candidates are predicted by num_top_rules, rule
  # application is stopped; can be used in conjunction with "noisyor" to achieve
  # noisy-or top-h (https://arxiv.org/pdf/2309.00306.pdf)
  # recommended values: -1 under "maxplus"; 5 under "noisyor"
  num_top_rules: -1

  filter_w_data: True
  filter_w_target: True
  # choose between "random" / "frequency"
  tie_handling: "frequency"
  # -1 for using ALL available threads
  num_threads: -1 

# calculates answer candidates and scores based on 
# questions (h, r, ?) and (?, r, t)
qa_handler:
  # same as ranking_handler; can be retrieved with handler.get_rules(bool)
  # see documentation for data strucuture
  collect_rules: False
    # number of candidates to calculate
  topk: 100
  # select from "maxplus" / "noisyor"; see ranking handler
  aggregation_function: "maxplus"

  ### stopping criteria for rule application
  # see ranking_handler for description
  disc_at_least: 10 # -1 for off, must not be bigger than topk
  hard_stop_at: -1 #-1 for off
  num_top_rules: -1

  filter_w_data: True
  # choose between "random" / "frequency"
  tie_handling: "frequency"
  # -1 for using ALL available threads
  num_threads: -1 

# given input rules, calculates materialization (predictions)
# and stats (num_pred, num_true_preds)
rules_handler:
  # whether to store triple predictions 
  # and stats (num_pred, num_true)
  # to obtained with handler.get_predictions(bool), handler.get_statistics()
  collect_predictions: True
  collect_statistics: True
  num_threads: -1 #-1 for ALL available threads

# given input triples, calculates triple scores and can output all
# predicting rules + their groundings (explanations)
prediction_handler:
  collect_explanations: False
  # select from "maxplus" / "noisyor"
  # note that as we are not calculating candidate rankings; selecting maxplus simply
  # results in "max-aggregation" scores
  aggregation_function: "maxplus"
  # for a given triple stop rule application if it was predicted by the
  # num_top_rules with the highest confidences
  # set to -1 to not apply any stopping criterion, e.g., to apply all rules
  # if you want to only collect the best explanation for each triple, set to 1
  # note that the noisyor score is influenced by this parameter
  # and results in noisyor-top-h scores (https://arxiv.org/pdf/2309.00306.pdf)
  num_top_rules: 5 
  
  num_threads: -1 #-1 for ALL available threads


## clause options ############################################################

### Learns rules with AnyBURL or Amie
learner:
  # chose betweeen: "anyburl" / "amie"
  mode: "amie"  
  anyburl:
    # learning time in seconds for AnyBURL
    time: 60
    # any raw option supported by AnyBURL
    # can be set under 'raw' 
    raw:
      # max length of B-rules
      MAX_LENGTH_CYCLIC: 3
      # don't learn rules with support < 2
      THRESHOLD_CORRECT_PREDICTIONS: 2
      # dont learn rules with confidence smaller 0.0001
      THRESHOLD_CONFIDENCE: 0.0001
      # for learning rules with only particular relations in the head
      # use SINGLE_RELATIONS: rel1,rel2
  amie:
    # any raw option supported by Amie can be set under raw
    raw:
      # for PyClause support, don't modify "bias"
      # and don't modify "oftm"
      bias: amie.mining.assistant.pyclause.AnyBurlMiningAssistant
      ofmt: anyburl
      # some important parameters with their AMIE default values
      mins: 100
      minc: 0.0
      maxad: 3 # number of atoms = 1 head atom + body atoms
      minhc: 0.01
      minpca: 0.0
      # this is special notation, which adds the parameter to the call (as a flag) and omits the value of the param
      # by default constants are deactivated in AMIE
      # const: "*flag*" 
      # maxadc: 2 # number of atoms in rules with constants = 1 head atom + body atoms
      


### An experimental rule miner that efficiently mines rules simultaneously
### it is very efficient for mining all U_c rules; less efficient for cyclical rules (B-rules)
torm_learner:
  #  choose betweeen "hybrid" / "torm"
  # 'hybrid' calculates rule confidences for cyclical rules (B-Rules) with AnyBURL confidence sampling;
  #  when selected hybrid then torm options and learner.anyburl options apply; use anyburl.time 
  #  for the learning time of B-rules
  # 'torm' calculates rule confidences for B-rules with c_clause.RulesHandler materialization
  mode: "torm"  
  torm:
    # if set to false, rules that do not make any wrong prediction are suppressed
    tautology: False 
    # rule type options
    b:
      active: True
      confidence: 0.0001
      support: 2
      length: 3
      batchsize: 1000
    uc:
      active: True
      confidence: 0.0001
      support: 2
    ud:
      active: True
      confidence: 0.0001
      support: 2
    z:
      active: True
      confidence: 0.0001
      support: 2
    xx_uc:
      active: True
      confidence: 0.0001
      support: 2
    xx_ud:
      active: True
      confidence: 0.0001
      support: 2

io:
  rule_format: "PyClause"